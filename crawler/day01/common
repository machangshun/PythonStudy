Day01
1.爬虫介绍
1.1大数据时代
数据获取方式
1.企业生产的用户数据：66条
大数据的获取量非常多
2.数据管理咨询公司
3.政府机构提供的公开数据
4.第三方数据平台购买
5.爬虫爬取数据

1.2什么是爬虫
爬取网页数据的程序

1.3爬虫怎么抓取网页数据
网页三大特征
网页都有URL统一资源定位符
www.tmall.com==>ip地址
2.网页都使用HTML
3.网页都使用HTTP/HTTPS（超文本传输协议）
互联网传输协议
HTTP:最原始的传输协议
HTTPS：最新的传输协议 拥有SSL加密层
防止网络爬虫
1.4爬虫的设计思路
1.首先确定需要爬取的网页URL地址
2.通过HTTP/HTTPS协议来获取对应的HTML网页
3.提取HTML页里面有用的数据
a.如果有需要的数据 保存起来
b.如果是页面里的其他URL，那么继续执行第二步
1.5为什么选python

2.爬虫课程介绍
1.python基本语法知识
2.如何抓取HTML页面
urllib urllib2 request
3.解析服务器响应内容
re xpath bs4 jsonpath pyquery
4.采取动态HTML 验证码的处理
5.scrapy框架
6.分布式策略
7.爬虫 和反爬虫 反反爬虫之间的斗争
cmd==>pip install bs4

3.通用爬虫
1.通用爬虫：搜索引擎用的爬虫系统
1.1目标尽可能地将所有地网页下载下来，服务器备份提取关键字 最后提供一个用户检索
1.2获取新网站地URL
1.主动提交
2.网站外链
3.搜索引擎和DNS服务商合作商合作
92.168.27.30：8080==》URL
www.zhang.com
1.3通用爬虫不是什么都能爬
Robots协议
协议规定的能爬
协议可以爬取的内容有robots.txt中查看
1.4搜索引擎排名
1.根据流量排名
2.竞价排名
莆田医院 事件
1.5通用排名的缺点
1.只能提供和文本相关的内容
2.提供的结果前篇一律 没有针对性
3.不能理解人类语言上的检索

4.聚焦爬虫
爬虫程序员针对某种的内容爬取
User-Agent:是爬虫和反爬斗争的第一步
response:是服务器响应的类文件
*返回HTTP的响应码，成功返回200
*4服务器页面出错 404 405
*5服务器问题
实际数据的实际URL，防止重定向问题
返回服务器响应的HTTP报头
GMT：格林尼治时间
格林尼治天文台
1970-1-1 0：0 格林尼治原始事件
经度分割线
电脑的时间 全部是
2019-11-14 10:53:30 - 1970-1-1 0:0
毫秒
.com 互联网 服务器连在一块9台 美国 2台英国
.cn 1台 中国 中国 政府网站.cn
edu.cn 中国服务器

5.User-Agent历史
Mosaic:
Netscape网景：
IE：
Mozilla基金组织：Firefox火狐浏览器
第一款具有浏览器内核
IE:微软公司
Opera:
Linux组织：KHTML（like Gecko）
Apple公司：WebKit(like KHTML)
Google公司：Google
IE/360/Chrome/FireFox/搜狗 猎豹
遨游 百度 UC QQ

课后作业：
1爬取小说网站一个章节
1.1数据进行解析
1.2只包含文字
1.3将文字存储到文本中
2.爬取小说 所有章节
并存储文本中
文件名称 01-水鬼拦路.txt
02-....txt




